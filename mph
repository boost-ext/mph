//
// Copyright (c) 2024 Kris Jusiak (kris at jusiak dot net)
//
// Distributed under the Boost Software License, Version 1.0.
// (See accompanying file LICENSE_1_0.txt or copy at
// http://www.boost.org/LICENSE_1_0.txt)
//
#ifndef MPH
#define MPH 2'3'0 // SemVer
#pragma GCC system_header

/**
 * [Minimal] Perfect hash library (https://github.com/boost-ext/mph)
 */
namespace mph::inline v2_3_0 {
using u8  = __UINT8_TYPE__;
using u16 = __UINT16_TYPE__;
using u32 = __UINT32_TYPE__;
using u64 = __UINT64_TYPE__;

namespace utility {
template<class T1, class T2>
struct compressed_pair {
  using first_type = T1;
  using second_type = T2;
  [[no_unique_address]] T1 first;
  [[no_unique_address]] T2 second;
};
template<class T1, class T2> compressed_pair(T1, T2) -> compressed_pair<T1, T2>;

template<class T, u32 Size>
struct array {
  using value_type = T;
  [[nodiscard]] constexpr const T* data() const noexcept { return data_; }
  [[nodiscard]] constexpr T* data() noexcept { return data_; }
  [[nodiscard]] constexpr auto begin() const noexcept { return &data_[0]; }
  [[nodiscard]] constexpr auto begin() noexcept { return &data_[0]; }
  [[nodiscard]] constexpr auto end() const noexcept { return &data_[0] + Size; }
  [[nodiscard]] constexpr auto end() noexcept { return &data_[0] + Size; }
  [[nodiscard]] constexpr auto size() const noexcept { return Size; }
  [[nodiscard]] constexpr const auto& operator[](u32 i) const noexcept { return data_[i]; }
  [[nodiscard]] constexpr auto& operator[](u32 i) noexcept { return data_[i]; }
  constexpr void fill(const T& value) noexcept { for (auto i = 0u; i < Size; ++i) { data_[i] = value; } }
  T data_[Size];
};
template<class T, class... Ts> array(T, Ts...) -> array<T, 1u + sizeof...(Ts)>;

namespace detail {
template <bool> struct conditional;
template <> struct conditional<false> { template <class, class T> using fn = T; };
template <> struct conditional<true>  { template <class T, class> using fn = T; };
} // namespace detail
template <bool B, class T, class F>
using conditional_t = typename detail::conditional<B>::template fn<T, F>;

template<class T, T v>
struct integral_constant {
  using type = integral_constant;
  using value_type = T;
  static constexpr T value = v;
  constexpr operator value_type() const noexcept { return value; }
};

template<class T, u32 alignment>
struct aligned {
  using type = struct alignas(alignment) a  : T { };
  static_assert(alignment == alignof(type));
};
template<class T> struct aligned<T, u32{}> { using type = T; };
template<class T, u32 alignment>
using aligned_t = typename aligned<T, alignment>::type;

template<class T, u32 width>
using simd_t __attribute__ ((vector_size(width))) = T;
} // namespace utility

template<class T>
[[nodiscard]] [[gnu::always_inline]] constexpr auto pext(const T a, const auto mask) noexcept -> T {
  // https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=pext
  if (constexpr T size = sizeof(T) * __CHAR_BIT__; __builtin_is_constant_evaluated()) {
    T result{};
    T m = mask;
    auto k = 0u;
    for (T i{}; i < size; ++i) {
      if (m & 1) result |= ((a >> i) & 1) << k++;
      m >>= 1;
    }
    return result;
  }
  #if defined(__BMI2__)
  else if constexpr (requires { u32{a}; u32{mask}; }) { return __builtin_ia32_pext_si(a, mask); }
  else if constexpr (requires { u64{a}; u64{mask}; }) { return __builtin_ia32_pext_di(a, mask); }
  #endif
  else if constexpr (requires { mask.value; }) {
    // https://github.com/intel/compile-time-init-build/blob/main/include/lookup/pseudo_pext_lookup.hpp
    return [&] {
      static constexpr auto nbits = __builtin_popcountl(mask);
      static constexpr auto cbits = size - nbits -
        (sizeof(mask.value) <= sizeof(u32) ? __builtin_clz(mask) : __builtin_clzl(mask));
      static constexpr auto coefficient = [&] {
        auto set = false;
        auto dst = cbits;
        T result{};
        for (auto i = 0u; i < size; ++i) {
          const auto curr = ((T(1) << i) & mask) != T();
          if (curr and not set) result = result | (T(1) << (dst - i));
          dst += curr;
          set = curr;
        }
        return result;
      }();
      return ((a & mask) * coefficient >> cbits) & ((T(1) << nbits) - T(1));
    }();
  }
  return {};
}

template<class T, u32 N = 1u>
[[nodiscard]] constexpr auto mask(const auto& v) noexcept -> T {
  utility::array<T, decltype(v){}.size()> vs;
  T max{};
  u32 size{};
  for (auto i = 0u; i < vs.size(); ++i) {
    if (not v[i].first) break;
    if (vs[i] = v[i].first; vs[i] > max) max = vs[i];
    ++size;
  }
  constexpr auto H = (N * vs.size()) << 1u;
  constexpr auto N_ = N - 1u;
  const auto clz = sizeof(max) <= sizeof(u32) ? __builtin_clz(max) : __builtin_clzl(max);
  const auto nbits = sizeof(T) * __CHAR_BIT__ - clz - 1u;
  utility::array<T, H> hashed;
  T mask = ((T(1) << nbits) - 1u);
  for (int i = nbits; i >= 0; --i) {
    mask &= ~(T(1) << i);
    hashed = {};
    for (auto j = 0u; j < size; ++j) {
      const auto masked = (vs[j] & mask) + 1u;
      auto slot = masked % H;
      auto n = N_;
      auto found = false;
      while (hashed[slot]) {
        if (hashed[slot] == masked and not n--) {
          found = true;
          break;
        }
        slot = (slot + 1u) % H;
      }
      if (found) {
        mask |= (T(1) << i);
        break;
      }
      hashed[slot] = masked;
    }
  }
  return mask;
}

template<class T>
[[nodiscard]] [[gnu::always_inline]] constexpr auto to(const auto& data) noexcept -> T {
  if (__builtin_is_constant_evaluated()) {
    if constexpr (requires { data.data(); data.size(); }) {
      T t{};
      for (auto i = 0u; i < data.size(); ++i) {
        t = (t << __CHAR_BIT__) | data.data()[data.size() - i - 1u];
      }
      return t;
    } else if constexpr (requires { data[0]; }) {
      auto size = 0u;
      auto ptr = data;
      while (*ptr++) size++;
      T t{};
      for (auto i = 0u; i < size; ++i) {
        t = (t << __CHAR_BIT__) | data[size - i - 1u];
      }
      return t;
    } else {
      return data;
    }
  } else if constexpr (requires { T{data}; }) {
    return data;
  } else if constexpr (requires { data.data(); data.size(); }) {
    #if not defined(MPH_PAGE_SIZE)
    #define MPH_PAGE_SIZE 4096u // [optimization] if set __builtin_memcpy(data, sizeof(T)) & bzhi(size)
                                //                if not __builtin_memcpy(data, size)
    #endif
    if constexpr (requires { []<template<class, auto> class T_, class _, auto size>(T_<_, size>){}(data); }) {
      if constexpr (constexpr auto size = decltype(data){}.size(); size == sizeof(T)) {
        return *__builtin_bit_cast(const T*, data.data());
      } else if constexpr (size > 0u and size <= sizeof(T)) {
        T t{};
        __builtin_memcpy(&t, data.data(), size);
        return t;
      }
    } else if constexpr (MPH_PAGE_SIZE) {
      // https://github.com/bminor/glibc/blob/master/sysdeps/generic/memcopy.h#L162
      if ((u64(data.data()) & (MPH_PAGE_SIZE - 1ul)) >= (MPH_PAGE_SIZE - sizeof(T))) [[unlikely]] { // page boundry
        return [&data] [[gnu::cold]] {
          T t{};
          __builtin_memcpy(&t, data.data(), data.size());
          return t;
        }();
      }
      T t;
      __builtin_memcpy(&t, data.data(), sizeof(t)); // not at page boundry
      const auto index = T(data.size() * __CHAR_BIT__);
      #if defined(__BMI2__)
      if constexpr (sizeof(t) <= sizeof(u32)) {
        return __builtin_ia32_bzhi_si(t, index);
      } else if constexpr (sizeof(t) <= sizeof(u64)) {
        return __builtin_ia32_bzhi_di(t, index);
      }
      #else
      return t & ((T(1) << index) - T(1));
      #endif
    } else {
      T t{};
      __builtin_memcpy(&t, data.data(), data.size());
      return t;
    }
  }
  return {};
}

namespace concepts {
template<auto cfg> concept config = requires {
  cfg.probability;
  cfg.lookup;
  cfg.alignment;
} and (
  cfg.probability >= 0u and
  cfg.probability <= 100u and
  cfg.lookup >= 0u and
  not (cfg.alignment % 2)
);

template<auto kv> concept range = requires(u32 n) {
  kv.size();
  kv.begin();
  kv.end();
  kv[n];
};
} // namespace concepts

template<auto kv>
struct config {
  /// 0         - none of the input data can be found in the kv
  /// (0, 50)   - input data is unlikely to be found in the kv
  /// 50        - unpredictable (default)
  /// (50, 100) - input data is likely to be found in the kv
  /// 100       - all input data can be found in the kv
  u8 probability{50};

  /// 0 - simd not used
  /// N - simd width
  u32 simd_width{[] {
    #if defined(__AVX2__)
    return 256u / __CHAR_BIT__;
    #else
    return 0u;
    #endif
  }()};

  /// 1 - one element per lookup (faster but larger memory footprint)
  /// N - n elements per lookup  (slower but smaller memory footprint)
  u32 lookup{
    [this]() -> u32 {
      using key_type = typename decltype(kv)::value_type::first_type;
      if (sizeof(key_type) == sizeof(u32) and
          kv.size() <= sizeof(key_type) * (1u << 10u)) {
        return 1u;
      } else if (sizeof(key_type) == sizeof(u64) and
                 kv.size() <= sizeof(key_type) * (1u << 7u)) {
        return 1u;
      } else if (probability == 100u) {
        return 2u * sizeof(key_type) - 4u;
      } else if (sizeof(key_type) < simd_width) {
        return simd_width / sizeof(key_type);
      } else {
        return 2u * sizeof(key_type) - 4u;
      }
    }()
  };

  /// 0 - no alignment for the lookup table
  /// n - alignas(lookup) - needs to be power of 2, required for simd
  u32 alignment{simd_width / 4u};
};

template<auto kv, auto cfg = config<kv>{}>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() == 0u or
    cfg.probability == 0u
  )
[[nodiscard]] constexpr auto hash([[maybe_unused]] const auto& key) noexcept -> typename decltype(kv)::value_type::second_type {
  return {};
}

template<auto kv, auto cfg = config<kv>{}>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() == 1u and
    cfg.probability > 0u and cfg.probability < 100u
  )
[[nodiscard]] constexpr auto hash(const auto& key) noexcept -> typename decltype(kv)::value_type::second_type {
  using key_type = typename decltype(kv)::value_type::first_type;
  using value_type = typename decltype(kv)::value_type::second_type;
  return to<key_type>(key) == kv[0].first ? kv[0].second : value_type{};
}

template<auto kv, auto cfg = config<kv>{}, class T, auto Size>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() > 1u and
    cfg.probability > 0u
  )
[[nodiscard]] consteval auto hash(const T (&key)[Size]) noexcept -> typename decltype(kv)::value_type::second_type {
  using key_type = typename decltype(kv)::value_type::first_type;
  for (auto&& lhs = to<key_type>(key); const auto& [key, value] : kv) { if (lhs == key) { return value; } }
  return {};
}

template<auto kv, auto cfg = config<kv>{}, template<class T, T> class T, class TKey, TKey key>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() > 1u and
    cfg.probability > 0u
  )
[[nodiscard]] consteval auto hash(const T<TKey, key>&) noexcept -> typename decltype(kv)::value_type::second_type {
  for (const auto& [k, value] : kv) { if (key == k) { return value; } }
  return {};
}

template<auto kv, auto cfg = config<kv>{}>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() > 1u and
    cfg.probability == 100u and
    cfg.lookup == 1u
  )
[[nodiscard]] [[gnu::always_inline]]
inline auto hash(const auto& key) noexcept -> typename decltype(kv)::value_type::second_type {
  using key_type = typename decltype(kv)::value_type::first_type;
  using value_type = typename decltype(kv)::value_type::second_type;
  using mask_type = utility::conditional_t<sizeof(key_type) <= sizeof(u32), u32, u64>;
  static constexpr const auto mask = utility::integral_constant<mask_type, mph::mask<key_type, cfg.lookup>(kv)>{};
  static constexpr const auto lookup = [] {
    utility::aligned_t<
      utility::array<
        value_type,
        mask_type(1) << __builtin_popcountl(mask)
      >,
      cfg.alignment
    > lookup{};
    for (const auto& [key, value] : kv) {
      lookup[pext(key, mask)] = value;
    }
    return lookup;
  }();
  return lookup[pext(to<key_type>(key), mask)];
}

template<auto kv, auto cfg = config<kv>{}>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() > 1u and
    cfg.probability > 0u and cfg.probability < 100u and
    cfg.lookup == 1u
  )
[[nodiscard]] [[gnu::always_inline]]
inline auto hash(const auto& key) noexcept -> typename decltype(kv)::value_type::second_type {
  using key_type = typename decltype(kv)::value_type::first_type;
  using value_type = typename decltype(kv)::value_type::second_type;
  using mask_type = utility::conditional_t<sizeof(key_type) <= sizeof(u32), u32, u64>;
  static constexpr const auto mask = utility::integral_constant<mask_type, mph::mask<key_type, cfg.lookup>(kv)>{};
  static constexpr const auto lookup = [] {
    utility::aligned_t<
      utility::array<
        utility::compressed_pair<key_type, value_type>,
        mask_type(1) << __builtin_popcountl(mask)
      >,
      cfg.alignment
    > lookup{};
    for (const auto& [key, value] : kv) {
      lookup[pext(key, mask)] = utility::compressed_pair{key, value};
    }
    return lookup;
  }();

  auto&& lhs = to<key_type>(key);
  auto&& rhs = lookup[pext(lhs, mask)];
  #if __has_builtin(__builtin_unpredictable)
  if constexpr (cfg.probability == 50u) {
    if (__builtin_unpredictable(lhs == rhs.first)) {
      return rhs.second;
    }
  }
  else
  #endif
  if (__builtin_expect_with_probability(lhs == rhs.first, 1,
    [] { return float(cfg.probability) / float(100u); }())) {
    return rhs.second;
  }
  return {};
}

#if __has_builtin(__builtin_ia32_movmskps256) or \
    __has_builtin(__builtin_ia32_movmskps256)
template<auto kv, auto cfg = config<kv>{}>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() > 1u and
    cfg.probability > 0u and cfg.probability < 100u and
    cfg.lookup > 1u and
    cfg.lookup <= cfg.simd_width / sizeof(typename decltype(kv)::value_type::first_type) and
    cfg.alignment > 0u
  )
[[nodiscard]] [[gnu::always_inline]]
inline auto hash(const auto& key) noexcept -> typename decltype(kv)::value_type::second_type {
  using key_type = typename decltype(kv)::value_type::first_type;
  using value_type = typename decltype(kv)::value_type::second_type;
  using mask_type = utility::conditional_t<sizeof(key_type) <= sizeof(u32), u32, u64>;
  static constexpr const auto mask = utility::integral_constant<mask_type, mph::mask<key_type, cfg.lookup>(kv)>{};
  static constexpr const auto lookup = [] {
    utility::aligned_t<
      utility::array<
        utility::compressed_pair<
          utility::aligned_t<
            utility::array<key_type, cfg.lookup>,
            cfg.alignment
          >,
          utility::aligned_t<
            utility::array<
              value_type,
              1u + (1u << (cfg.lookup - 1u))
            >,
            cfg.alignment
          >
        >,
        mask_type(1) << __builtin_popcountl(mask)
      >,
      cfg.alignment
    > lookup{};
    for (const auto& [key, value] : kv) {
      auto& slot = lookup[pext(key, mask)];
      auto n = 0u;
      while (slot.first[n]) n++;
      slot.first[n] = key;
      slot.second[1u << n] = value;
    }
    return lookup;
  }();

  auto&& lhs = to<key_type>(key);
  auto&& rhs = lookup[pext(lhs, mask)];
  auto&& cmp = lhs == *(utility::simd_t<key_type, cfg.simd_width>*)rhs.first.data();

  if constexpr (sizeof(key_type) == sizeof(u32)) {
    return rhs.second[__builtin_ia32_movmskps256(utility::simd_t<float, cfg.simd_width>(cmp))];
  } else if constexpr (sizeof(key_type) == sizeof(u64)) {
    return rhs.second[__builtin_ia32_movmskpd256(utility::simd_t<double, cfg.simd_width>(cmp))];
  }
}
#endif

template<auto kv, auto cfg = config<kv>{}>
  requires concepts::range<kv> and concepts::config<cfg> and (
    kv.size() > 1u and
    cfg.probability > 0u and
    cfg.lookup > 1u and
    cfg.lookup > cfg.simd_width / sizeof(typename decltype(kv)::value_type::first_type)
  )
[[nodiscard]] [[gnu::always_inline]]
inline auto hash(const auto& key) noexcept -> typename decltype(kv)::value_type::second_type {
  using key_type = typename decltype(kv)::value_type::first_type;
  using value_type = typename decltype(kv)::value_type::second_type;
  using mask_type = utility::conditional_t<sizeof(key_type) <= sizeof(u32), u32, u64>;
  static constexpr const auto mask = utility::integral_constant<mask_type, mph::mask<key_type, cfg.lookup>(kv)>{};
  static constexpr const auto lookup = [] {
    utility::array<
      utility::array<
        utility::compressed_pair<key_type, value_type>,
        cfg.lookup
      >,
      mask_type(1) << __builtin_popcountl(mask)
    > lookup{};
    for (const auto& [key, value] : kv) {
      auto& slot = lookup[pext(key, mask)];
      auto n = 0u;
      while (slot[n].first) n++;
      slot[n] = utility::compressed_pair{key, value};
    }
    return lookup;
  }();
  static constexpr const auto masks = [] {
    utility::array<mask_type, lookup.size()> masks{};
    int max_count{};
    for (auto i = 0u; i < lookup.size(); ++i) {
      if (const auto& slot = lookup[i]; slot[0].first) {
        const auto mask = mph::mask<key_type, 1u>(slot);
        if (const auto count = __builtin_popcountl(mask); count > max_count) {
          max_count = count;
        }
        masks[i] = mask;
      }
    }
    return utility::compressed_pair{masks, max_count};
  }();
  static constexpr const auto lookups = [] {
    utility::aligned_t<
      utility::array<
        utility::compressed_pair<
          mask_type,
          utility::aligned_t<
            utility::array<
              utility::conditional_t<
                cfg.probability == 100u,
                value_type,
                utility::compressed_pair<key_type, value_type>
              >,
              mask_type(1) << masks.second
            >,
            cfg.alignment
          >
        >,
        masks.first.size()
      >,
      cfg.alignment
    > lookups{};

    const auto fill = [&](auto fn) {
      for (auto i = 0u; i < masks.first.size(); ++i) {
        if (auto& slot = lookups[i]; lookup[i][0].first) {
          slot.first = masks.first[i];
          for (const auto& [key, value] : lookup[i]) {
            if (not key) break;
            slot.second[pext(key, slot.first)] = fn(key, value);
          }
        }
      }
    };

    if constexpr (cfg.probability == 100u) {
      fill([]([[maybe_unused]] const auto& key, const auto& value) { return value; });
    } else {
      fill([](const auto& key, const auto& value) { return utility::compressed_pair{key, value}; });
    }
    return lookups;
  }();

  auto&& lhs = to<key_type>(key);
  auto&& lut = lookups[pext(lhs, mask)];
  auto&& rhs = lut.second[pext(lhs, lut.first)];
  if constexpr (requires { rhs.first; rhs.second; }) {
    #if __has_builtin(__builtin_unpredictable)
      if constexpr (cfg.probability == 50u) {
        if (__builtin_unpredictable(lhs == rhs.first)) {
          return rhs.second;
        }
      }
      else
      #endif
      if (__builtin_expect_with_probability(lhs == rhs.first, 1,
        [] { return float(cfg.probability) / float(100u); }())) {
        return rhs.second;
      }
  } else {
    return rhs;
  }
  return {};
}
} // namespace mph

#if not defined(DISABLE_STATIC_ASSERT_TESTS)
static_assert(([] {
  constexpr auto expect = [](bool cond) { if (not cond) { void failed(); failed(); } };

  // mph::utility::compressed_pair
  {
    static_assert(1 == mph::utility::compressed_pair{1, 2}.first);
    static_assert(2 == mph::utility::compressed_pair{1, 2}.second);
    static_assert(sizeof(int) + sizeof(int) == sizeof(mph::utility::compressed_pair{int{}, int{}}));
    struct empty { };
    static_assert(sizeof(int) == sizeof(mph::utility::compressed_pair{empty{}, 42}));
    static_assert(sizeof(int) == sizeof(mph::utility::compressed_pair{42, empty{}}));
    static_assert(sizeof(empty) + sizeof(empty) == sizeof(mph::utility::compressed_pair{empty{}, empty{}}));
  }

  // mph::utility::array
  {
    {
      mph::utility::array<mph::u32, 1> a{};
      expect(1 == a.size());
    }

    {
      mph::utility::array a{1, 2};
      expect(2u == a.size());
      expect(1 == a[0]);
      expect(2 == a[1]);
    }

    {
      mph::utility::array a{1};
      a[0] = 2;
      expect(2 == a[0]);
    }

    {
      mph::utility::array a{1, 2, 3};
      expect(3u == a.size());
      expect(a.begin() != a.end());
      expect(a.size() == mph::u32(a.end() - a.begin()));
      expect(a.end() == a.begin() + a.size());
    }
  }

  // mph::utility::integral_constant
  {
    static_assert(0 == mph::utility::integral_constant<int, 0>::value);
    static_assert(42 == mph::utility::integral_constant<int, 42>{});
    static_assert(42u == mph::utility::integral_constant<unsigned, 42u>::value);
    static_assert('X' == mph::utility::integral_constant<char, 'X'>::value);
  }

  // mph::utility::aligned_t
  {
    using mph::utility::array;

    static_assert(16u == alignof(mph::utility::aligned_t<array<int, 42>, 16u>));
    static_assert(32u == alignof(mph::utility::aligned_t<array<int, 42>, 32u>));
    static_assert(64u == alignof(mph::utility::aligned_t<array<int, 42>, 64u>));
    static_assert(alignof(int) == alignof(mph::utility::aligned_t<array<int, 42>, 0u>));
  }

  // mph::pext
  {
    using mph::u32;

    static_assert(0    == mph::pext(0b00, 0b00));
    static_assert(0    == mph::pext(0b01, 0b00));
    static_assert(0b1  == mph::pext(0b01, 0b01));
    static_assert(0b01 == mph::pext(0b01, 0b11));
    static_assert(0b0  == mph::pext(0b01, 0b10));
    static_assert(0b1  == mph::pext(0b11, 0b10));
    static_assert(0b1  == mph::pext(0b11, 0b01));
    static_assert(0b11 == mph::pext(0b11, 0b11));
  }

  // mph::mask
  {
    using mph::u32;
    using mph::utility::array;
    using mph::utility::compressed_pair;

    static_assert(0b01 == mph::mask<u32, 1u>(array{compressed_pair{0b10, 0}, compressed_pair{0b11, 0}}));
    static_assert(0b10 == mph::mask<u32, 1u>(array{compressed_pair{0b01, 0}, compressed_pair{0b11, 0}}));
    static_assert(0b10 == mph::mask<u32, 1u>(array{compressed_pair{0b11, 0}, compressed_pair{0b01, 0}}));
    static_assert(0b01 == mph::mask<u32, 1u>(array{compressed_pair{0b11, 0}, compressed_pair{0b10, 0}}));
    static_assert(0b01 == mph::mask<u32, 1u>(array{compressed_pair{0b01, 0}, compressed_pair{0b10, 0}}));
    static_assert(0b01 == mph::mask<u32, 1u>(array{compressed_pair{0b10, 0}, compressed_pair{0b01, 0}}));
    static_assert(0b11 == mph::mask<u32, 1u>(array{compressed_pair{0b11, 0}, compressed_pair{0b11, 0}}));
  }

  // mph::to
  {
    using mph::u32;
    using mph::utility::array;

    static_assert(0 == mph::to<u32>(0));
    static_assert(42 == mph::to<u32>(42));
    static_assert(42u == mph::to<u32>(42u));
    static_assert(0 == mph::to<u32>(""));
    static_assert((u32('A') << 0) + (u32('B') << __CHAR_BIT__) == mph::to<u32>("AB"));
    static_assert((u32('A') << 0) + (u32('B') << __CHAR_BIT__) + (u32('C') << __CHAR_BIT__*2) == mph::to<u32>("ABC"));
    static_assert((u32('A') << 0) + (u32('B') << __CHAR_BIT__) == mph::to<u32>(array{'A','B'}));
    static_assert((u32('A') << 0) + (u32('B') << __CHAR_BIT__) + (u32('C') << __CHAR_BIT__*2) == mph::to<u32>(array{'A','B','C'}));
  }

  // mph::concepts
  {
    // mph::concepts::config
    {
      struct cfg1{ };
      struct cfg2{ int probability{}; };
      struct cfg3{ int probability{}; int alignment{}; };
      struct cfg4{ int probability{}; int lookup{}; int alignment{}; };

      static_assert(not mph::concepts::config<cfg1{}>);
      static_assert(not mph::concepts::config<cfg2{}>);
      static_assert(not mph::concepts::config<cfg3{}>);
      static_assert(not mph::concepts::config<cfg4{.probability = -1, .lookup = {}, .alignment = {}}>);
      static_assert(not mph::concepts::config<cfg4{.probability = {}, .lookup = {}, .alignment = 1u}>);
      static_assert(mph::concepts::config<cfg4{}>);
      static_assert(mph::concepts::config<cfg4{.probability = 50, .lookup = {}, .alignment = 8u}>);
      static_assert(mph::concepts::config<cfg4{.probability = 50, .lookup = 4u, .alignment = 8u}>);
    }

    // mph::concepts::range
    {
      using mph::u32;

      struct range1 { };
      struct range2 { u32 begin() const; u32 end() const; };
      struct range3 { u32 begin() const; u32 end() const; u32 operator[](u32) const; };
      struct range4 { u32 begin() const; u32 end() const; u32 size() const; u32 operator[](u32) const; };

      static_assert(not mph::concepts::range<range1{}>);
      static_assert(not mph::concepts::range<range2{}>);
      static_assert(not mph::concepts::range<range3{}>);
      static_assert(mph::concepts::range<range4{}>);
    }
  }

  // mph::hash
  {
    using mph::u32;
    using mph::utility::compressed_pair;
    using mph::utility::array;
    using mph::utility::integral_constant;

    // integral
    {
      {
        constexpr array kv{
          compressed_pair{u32(4), u32(2)},
        };

        static_assert(0 == mph::hash<kv>(integral_constant<u32, 0>{}));
        static_assert(0 == mph::hash<kv>(integral_constant<u32, 1>{}));
        static_assert(2 == mph::hash<kv>(integral_constant<u32, 4>{}));
      }

      {
        constexpr array kv{
          compressed_pair{u32(4), u32(2)},
          compressed_pair{u32(42), u32(87)},
          compressed_pair{u32(100), u32(100)},
        };

        static_assert(0 == mph::hash<kv>(integral_constant<u32, 0>{}));
        static_assert(2 == mph::hash<kv>(integral_constant<u32, 4>{}));
        static_assert(87 == mph::hash<kv>(integral_constant<u32, 42>{}));
        static_assert(100 == mph::hash<kv>(integral_constant<u32, 100>{}));
      }
    }

    // string-like
    {
      {
        constexpr array kv{
          compressed_pair{mph::to<u32>("BTC"), 1},
          compressed_pair{mph::to<u32>("ETH"), 2},
          compressed_pair{mph::to<u32>("XRP"), 3},
        };

        static_assert(0 == mph::hash<kv>(""));
        static_assert(1 == mph::hash<kv>("BTC"));
        static_assert(2 == mph::hash<kv>("ETH"));
        static_assert(3 == mph::hash<kv>("XRP"));
      }
    }
  }
}(), true));
#endif
#endif // MPH
